{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-To-End Handwriting Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import importlib\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "import cv2\n",
    "import gluonnlp as nlp\n",
    "import leven\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from skimage import transform as skimage_tf, exposure\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ocr.utils.expand_bounding_box import expand_bounding_box\n",
    "from ocr.utils.sclite_helper import ScliteHelper\n",
    "from ocr.utils.word_to_line import sort_bbs_line_by_line, crop_line_images\n",
    "from ocr.utils.iam_dataset import IAMDataset, resize_image, crop_image, crop_handwriting_page\n",
    "from ocr.utils.encoder_decoder import Denoiser, ALPHABET, encode_char, decode_char, EOS, BOS\n",
    "from ocr.utils.beam_search import ctcBeamSearch\n",
    "\n",
    "import ocr.utils.denoiser_utils\n",
    "import ocr.utils.beam_search\n",
    "\n",
    "importlib.reload(ocr.utils.denoiser_utils)\n",
    "from ocr.utils.denoiser_utils import SequenceGenerator\n",
    "\n",
    "importlib.reload(ocr.utils.beam_search)\n",
    "from ocr.utils.beam_search import ctcBeamSearch\n",
    "\n",
    "\n",
    "from ocr.paragraph_segmentation_dcnn import SegmentationNetwork, paragraph_segmentation_transform\n",
    "from ocr.word_and_line_segmentation import SSD as WordSegmentationNet, predict_bounding_boxes\n",
    "from ocr.handwriting_line_recognition import Network as HandwritingRecognitionNet, handwriting_recognition_transform\n",
    "from ocr.handwriting_line_recognition import decode as decoder_handwriting, alphabet_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu(0) if mx.context.num_gpus() > 0 else mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation\n",
    "Obtain the original forms from the IAM dataset and plot the results. Randomly select 4 images for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading largeWriterIndependentTextLineRecognitionTask.zip: \n",
      "Completed: [------------------------------------------] 106%\n"
     ]
    }
   ],
   "source": [
    "test_ds = IAMDataset(\"form_original\", train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-65a42daa9b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigs_to_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/handwritten-text-recognition-for-apache-mxnet/ocr/utils/iam_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2086\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2088\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "figs_to_plot = 4\n",
    "images = []\n",
    "\n",
    "n = 0\n",
    "for i in range(0, figs_to_plot):\n",
    "    n = int(random.random()*len(test_ds))\n",
    "    image, _ = test_ds[n]\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(int(len(images)/2), 2, figsize=(15, 10 * len(images)/2))\n",
    "for i, image in enumerate(images):\n",
    "    y, x = int(i/2), int(i%2)\n",
    "    axs[y, x].imshow(image, cmap='Greys_r')\n",
    "    axs[y, x].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraph segmentation\n",
    "\n",
    "Given the image of a form in the IAM dataset, predict a bounding box of the handwriten component. The model was trained on using https://github.com/ThomasDelteil/Gluon_OCR_LSTM_CTC/blob/master/paragraph_segmentation_dcnn.py and an example is presented in https://github.com/ThomasDelteil/Gluon_OCR_LSTM_CTC/blob/master/paragraph_segmentation_dcnn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_segmentation_net = SegmentationNetwork(ctx=ctx)\n",
    "paragraph_segmentation_net.cnn.load_parameters(\"models/paragraph_segmentation2.params\", ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_segmentation_net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_size = (1120, 800)\n",
    "\n",
    "predicted_bbs = []\n",
    "\n",
    "fig, axs = plt.subplots(int(len(images)/2), 2, figsize=(15, 9 * len(images)/2))\n",
    "for i, image in enumerate(images):\n",
    "    s_y, s_x = int(i/2), int(i%2)\n",
    "    resized_image = paragraph_segmentation_transform(image, form_size)\n",
    "    bb_predicted = paragraph_segmentation_net(resized_image.as_in_context(ctx))\n",
    "    bb_predicted = bb_predicted[0].asnumpy()\n",
    "    bb_predicted = expand_bounding_box(bb_predicted, expand_bb_scale_x=0.03,\n",
    "                                           expand_bb_scale_y=0.03)\n",
    "    predicted_bbs.append(bb_predicted)\n",
    "    \n",
    "    axs[s_y, s_x].imshow(image, cmap='Greys_r')\n",
    "    axs[s_y, s_x].set_title(\"{}\".format(i))\n",
    "\n",
    "    (x, y, w, h) = bb_predicted\n",
    "    image_h, image_w = image.shape[-2:]\n",
    "    (x, y, w, h) = (x * image_w, y * image_h, w * image_w, h * image_h)\n",
    "    rect = patches.Rectangle((x, y), w, h, fill=False, color=\"r\", ls=\"--\")\n",
    "    axs[s_y, s_x].add_patch(rect)\n",
    "    axs[s_y, s_x].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "Crop the handwriting component out of the original IAM form.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_paragraph_size = (700, 700)\n",
    "fig, axs = plt.subplots(int(len(images)/2), 2, figsize=(15, 9 * len(images)/2))\n",
    "\n",
    "paragraph_segmented_images = []\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    s_y, s_x = int(i/2), int(i%2)\n",
    "\n",
    "    bb = predicted_bbs[i]\n",
    "    image = crop_handwriting_page(image, bb, image_size=segmented_paragraph_size)\n",
    "    paragraph_segmented_images.append(image)\n",
    "    \n",
    "    axs[s_y, s_x].imshow(image, cmap='Greys_r')\n",
    "    axs[s_y, s_x].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line/word segmentation\n",
    "\n",
    "Given a form with only handwritten text, predict a bounding box for each word. The model was trained with https://github.com/ThomasDelteil/Gluon_OCR_LSTM_CTC/blob/language_model/word_segmentation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_segmentation_net = WordSegmentationNet(2, ctx=ctx)\n",
    "word_segmentation_net.load_parameters(\"models/word_segmentation2.params\")\n",
    "word_segmentation_net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_c = 0.1\n",
    "overlap_thres = 0.1\n",
    "topk = 600\n",
    "\n",
    "fig, axs = plt.subplots(int(len(paragraph_segmented_images)/2), 2, \n",
    "                        figsize=(15, 5 * int(len(paragraph_segmented_images)/2)))\n",
    "predicted_words_bbs_array = []\n",
    "\n",
    "for i, paragraph_segmented_image in enumerate(paragraph_segmented_images):\n",
    "    s_y, s_x = int(i/2), int(i%2)\n",
    "\n",
    "    predicted_bb = predict_bounding_boxes(\n",
    "        word_segmentation_net, paragraph_segmented_image, min_c, overlap_thres, topk, ctx)\n",
    "\n",
    "    predicted_words_bbs_array.append(predicted_bb)\n",
    "    \n",
    "    axs[s_y, s_x].imshow(paragraph_segmented_image, cmap='Greys_r')\n",
    "    for j in range(predicted_bb.shape[0]):     \n",
    "        (x, y, w, h) = predicted_bb[j]\n",
    "        image_h, image_w = paragraph_segmented_image.shape[-2:]\n",
    "        (x, y, w, h) = (x * image_w, y * image_h, w * image_w, h * image_h)\n",
    "        rect = patches.Rectangle((x, y), w, h, fill=False, color=\"r\")\n",
    "        axs[s_y, s_x].add_patch(rect)\n",
    "        axs[s_y, s_x].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word to line image processing\n",
    "Algorithm to sort then group all words within a line together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_images_array = []\n",
    "fig, axs = plt.subplots(int(len(paragraph_segmented_images)/2), 2, \n",
    "                        figsize=(15, 9 * int(len(paragraph_segmented_images)/2)))\n",
    "\n",
    "for i, paragraph_segmented_image in enumerate(paragraph_segmented_images):\n",
    "    s_y, s_x = int(i/2), int(i%2)\n",
    "    axs[s_y, s_x].imshow(paragraph_segmented_image, cmap='Greys_r')\n",
    "    axs[s_y, s_x].axis('off')\n",
    "    axs[s_y, s_x].set_title(\"{}\".format(i))\n",
    "    \n",
    "    predicted_bbs = predicted_words_bbs_array[i]\n",
    "    line_bbs = sort_bbs_line_by_line(predicted_bbs, y_overlap=0.4)\n",
    "    line_images = crop_line_images(paragraph_segmented_image, line_bbs)\n",
    "    line_images_array.append(line_images)\n",
    "    \n",
    "    for line_bb in line_bbs:\n",
    "        (x, y, w, h) = line_bb\n",
    "        image_h, image_w = paragraph_segmented_image.shape[-2:]\n",
    "        (x, y, w, h) = (x * image_w, y * image_h, w * image_w, h * image_h)\n",
    "\n",
    "        rect = patches.Rectangle((x, y), w, h, fill=False, color=\"r\")\n",
    "        axs[s_y, s_x].add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwriting recognition\n",
    "Given each line of text, predict a string of the handwritten text. This network was trained with https://github.com/ThomasDelteil/Gluon_OCR_LSTM_CTC/blob/language_model/handwriting_line_recognition.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handwriting_line_recognition_net = HandwritingRecognitionNet(rnn_hidden_states=512,\n",
    "                                                             rnn_layers=2, ctx=ctx, max_seq_len=160)\n",
    "handwriting_line_recognition_net.load_parameters(\"models/handwriting_line8.params\", ctx=ctx)\n",
    "handwriting_line_recognition_net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_image_size = (60, 800)\n",
    "character_probs = []\n",
    "for line_images in line_images_array:\n",
    "    form_character_prob = []\n",
    "    for i, line_image in enumerate(line_images):\n",
    "        line_image = handwriting_recognition_transform(line_image, line_image_size)\n",
    "        line_character_prob = handwriting_line_recognition_net(line_image.as_in_context(ctx))\n",
    "        form_character_prob.append(line_character_prob)\n",
    "    character_probs.append(form_character_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Probalities to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arg_max(prob):\n",
    "    '''\n",
    "    The greedy algorithm convert the output of the handwriting recognition network\n",
    "    into strings.\n",
    "    '''\n",
    "    arg_max = prob.topk(axis=2).asnumpy()\n",
    "    return decoder_handwriting(arg_max)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beam_search(prob, width=5):\n",
    "    possibilities = ctcBeamSearch(prob.softmax()[0].asnumpy(), alphabet_encoding, None, width)\n",
    "    return possibilities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising the text output\n",
    "\n",
    "We use a seq2seq denoiser to translate noisy input to better output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_LEN = 150\n",
    "denoiser = Denoiser(alphabet_size=len(ALPHABET), max_src_length=FEATURE_LEN, max_tgt_length=FEATURE_LEN, num_heads=16, embed_size=256, num_layers=2)\n",
    "denoiser.load_parameters('models/denoiser2.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser.hybridize(static_alloc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a language model in order to rank the propositions from the denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_nlp = mx.gpu(3)\n",
    "language_model, vocab = nlp.model.big_rnn_lm_2048_512(dataset_name='gbw', pretrained=True, ctx=ctx_nlp)\n",
    "moses_tokenizer = nlp.data.SacreMosesTokenizer()\n",
    "moses_detokenizer = nlp.data.SacreMosesDetokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use beam search to sample the output of the denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_sampler = nlp.model.BeamSearchSampler(beam_size=20,\n",
    "                                           decoder=denoiser.decode_logprob,\n",
    "                                           eos_id=EOS,\n",
    "                                           scorer=nlp.model.BeamSearchScorer(),\n",
    "                                           max_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SequenceGenerator(beam_sampler, language_model, vocab, ctx_nlp, moses_tokenizer, moses_detokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_denoised(prob, ctc_bs=False):\n",
    "    if ctc_bs: # Using ctc beam search before denoising yields only limited improvements a is very slow\n",
    "        text = get_beam_search(prob)\n",
    "    else:\n",
    "        text = get_arg_max(prob)\n",
    "    src_seq, src_valid_length = encode_char(text)\n",
    "    src_seq = mx.nd.array([src_seq], ctx=ctx)\n",
    "    src_valid_length = mx.nd.array(src_valid_length, ctx=ctx)\n",
    "    encoder_outputs, _ = denoiser.encode(src_seq, valid_length=src_valid_length)\n",
    "    states = denoiser.decoder.init_state_from_encoder(encoder_outputs, \n",
    "                                                      encoder_valid_length=src_valid_length)\n",
    "    inputs = mx.nd.full(shape=(1,), ctx=src_seq.context, dtype=np.float32, val=BOS)\n",
    "    output = generator.generate_sequences(inputs, states, text)\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"This sentnce has an eror\"\n",
    "src_seq, src_valid_length = encode_char(sentence)\n",
    "src_seq = mx.nd.array([src_seq], ctx=ctx)\n",
    "src_valid_length = mx.nd.array(src_valid_length, ctx=ctx)\n",
    "encoder_outputs, _ = denoiser.encode(src_seq, valid_length=src_valid_length)\n",
    "states = denoiser.decoder.init_state_from_encoder(encoder_outputs, \n",
    "                                                  encoder_valid_length=src_valid_length)\n",
    "inputs = mx.nd.full(shape=(1,), ctx=src_seq.context, dtype=np.float32, val=BOS)\n",
    "print(sentence)\n",
    "print(\"Choice\")\n",
    "print(generator.generate_sequences(inputs, states, sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [AM] Arg Max CTC Decoding\n",
    "- [BS] Beam Search CTC Decoding\n",
    "- [D ] Adding Text Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, form_character_probs in enumerate(character_probs):\n",
    "    fig, axs = plt.subplots(len(form_character_probs) + 1, \n",
    "                            figsize=(10, int(1 + 2.3 * len(form_character_probs))))\n",
    "    for j, line_character_probs in enumerate(form_character_probs):\n",
    "        decoded_line_am = get_arg_max(line_character_probs)\n",
    "        print(\"[AM]\",decoded_line_am)\n",
    "        decoded_line_bs = get_beam_search(line_character_probs)\n",
    "        decoded_line_denoiser = get_denoised(line_character_probs, ctc_bs=False)\n",
    "        print(\"[D ]\",decoded_line_denoiser)\n",
    "        \n",
    "        line_image = line_images_array[i][j]\n",
    "        axs[j].imshow(line_image.squeeze(), cmap='Greys_r')            \n",
    "        axs[j].set_title(\"[AM]: {}\\n[BS]: {}\\n[D ]: {}\\n\\n\".format(decoded_line_am, decoded_line_bs, decoded_line_denoiser), fontdict={\"horizontalalignment\":\"left\", \"family\":\"monospace\"}, x=0)\n",
    "        axs[j].axis('off')\n",
    "    axs[-1].imshow(np.zeros(shape=line_image_size), cmap='Greys_r')\n",
    "    axs[-1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Results\n",
    "Iterative through the test data with the previous tests to obtain the total Character Error Rate (CER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclite = ScliteHelper('../SCTK/bin')\n",
    "\n",
    "def get_qualitative_results_lines(denoise_func):\n",
    "    sclite.clear()\n",
    "    test_ds_line = IAMDataset(\"line\", train=False)\n",
    "    for i in tqdm(range(1, len(test_ds_line))):\n",
    "        image, text = test_ds_line[i]\n",
    "        line_image = exposure.adjust_gamma(image, 1)\n",
    "        line_image = handwriting_recognition_transform(line_image, line_image_size)\n",
    "        character_probabilities = handwriting_line_recognition_net(line_image.as_in_context(ctx))\n",
    "        decoded_text = denoise_func(character_probabilities)\n",
    "        actual_text = text[0].replace(\"&quot;\", '\"').replace(\"&apos;\",\"'\").replace(\"&amp;\", \"&\")\n",
    "        sclite.add_text([decoded_text], [actual_text])\n",
    "    \n",
    "    cer, er = sclite.get_cer()\n",
    "    print(\"Mean CER = {}\".format(cer))\n",
    "    return cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qualitative_results(denoise_func):\n",
    "    sclite.clear()\n",
    "    for i in tqdm(range(1, len(test_ds))):\n",
    "        image, text = test_ds[i]\n",
    "        resized_image = paragraph_segmentation_transform(image, image_size=form_size)\n",
    "        paragraph_bb = paragraph_segmentation_net(resized_image.as_in_context(ctx))\n",
    "        paragraph_bb = paragraph_bb[0].asnumpy()\n",
    "        paragraph_bb = expand_bounding_box(paragraph_bb, expand_bb_scale_x=0.01,\n",
    "                                               expand_bb_scale_y=0.01)\n",
    "        paragraph_segmented_image = crop_handwriting_page(image, paragraph_bb, image_size=segmented_paragraph_size)\n",
    "        word_bb = predict_bounding_boxes(word_segmentation_net, paragraph_segmented_image, min_c, overlap_thres, topk, ctx)        \n",
    "        line_bbs = sort_bbs_line_by_line(word_bb, y_overlap=0.4)\n",
    "        line_images = crop_line_images(paragraph_segmented_image, line_bbs)\n",
    "\n",
    "        predicted_text = []\n",
    "        for line_image in line_images:\n",
    "            line_image = exposure.adjust_gamma(line_image, 1)\n",
    "            line_image = handwriting_recognition_transform(line_image, line_image_size)\n",
    "            character_probabilities = handwriting_line_recognition_net(line_image.as_in_context(ctx))\n",
    "            decoded_text = denoise_func(character_probabilities)\n",
    "            predicted_text.append(decoded_text)\n",
    "\n",
    "        actual_text = text[0].replace(\"&quot;\", '\"').replace(\"&apos;\",\"'\").replace(\"&amp;\", \"&\")\n",
    "        actual_text = actual_text.split(\"\\n\")\n",
    "        if len(predicted_text) > len(actual_text):\n",
    "            predicted_text = predicted_text[:len(actual_text)]\n",
    "        sclite.add_text(predicted_text, actual_text)\n",
    "    \n",
    "    cer, _ = sclite.get_cer()\n",
    "    print(\"Mean CER = {}\".format(cer))\n",
    "    return cer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CER with pre-segmented lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_qualitative_results_lines(get_arg_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_qualitative_results_lines(get_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CER full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_qualitative_results(get_arg_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_qualitative_results(get_beam_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_denoiser = get_qualitative_results(get_denoised)\n",
    "cer_denoiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ideas:\n",
    "    - weighted levenshtein\n",
    "    - re-trained the language model on GBW [~ didn't work too well]\n",
    "    - only penalize non-existing words\n",
    "    - Add single word training for denoiser\n",
    "    - having 2 best edit distance rather than single one\n",
    "    - split sentences based on punctuation\n",
    "    - use CTC loss for ranking\n",
    "    - meta model to learn to weight the scores from each thing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
